training: !!bool "true"
device: 4,5 #gpu id
seed: 777
---
data:
    train_path: './dataVoxCeleb1/Audio/dev/processed'
    train_path_unprocessed: './dataVoxCeleb1/Audio/dev/wav' #*/wav/speaker_id/session_id/file.wav
    test_meta_path: './dataVoxCeleb1/Metadata/veri_test.txt'
    test_path: './dataVoxCeleb1/Audio/test/processed'
    test_path_unprocessed: './dataVoxCeleb1/Audio/test/wav'
    feat_type: 'spec' #feature type: 'spec' (spectogram), 'logmel' (logmel spectogram)
    sr: 16000
    nfft: 512 #For mel spectrogram preprocess
    window: 0.025 #(s)
    hop: 0.01 #(s)
    nmels: 40 #Number of mel energies
    tisv_frame: 250 #Max number of time steps/frames in input after preprocess
---
model:
    type: 'TResNet34' #model type: 'TResNet32' (Thin ResNet34), 'RNN'
    hidden: 768 #Number of LSTM hidden layer units
    num_layer: 3 #Number of LSTM layers
    proj: 256 #Embedding size
    ghost_centers: 0
    vlad_centers: 10
    #Model path for testing, inference, or resuming training
    model_path: './speech_id_checkpoint/ckpt_epoch600_batchID151_modelTResNet34_spk8_utt8_featspec_lr0.1_optimAdadelta_lossge2e.pth'
---
train:
    N: 256 #Number of speakers in batch
    M: 1 #Number of utterances per speaker
    num_workers: 0 #number of workers for dataloader
    lr: 0.001
    optim: 'Adam' #optimizer type: 'Adam' (lr 0.001), 'SGD', 'Adadelta' (lr 0.1)
    loss: 'si' #loss type: "si" (Speaker identification), 'ge2e' (generaliazed E2E loss), 'hybrid'
    warmup_epochs: 1 #number of warmup epochs with lr set to lr/10
    wd: 0.0001 #weight decay
    epochs: 100 #Max training epoch
    patience: 10
    log_interval: 100 #Iterations before printing progress
    checkpoint_interval: 10 #Save model after x epochs
    checkpoint_dir: './speech_id_checkpoint'
    restore: !!bool "false" #Resume training from previous model path
