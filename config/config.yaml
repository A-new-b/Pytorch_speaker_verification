training: !!bool "true"
device: "7" #gpu id
---
data:
    train_path: './dataVoxCeleb1/Audio/dev/processed'
    train_path_unprocessed: './dataVoxCeleb1/Audio/dev/wav' #*/wav/speaker_id/session_id/file.wav
    test_meta_path: './dataVoxCeleb1/Metadata/veri_test.txt'
    test_path: './dataVoxCeleb1/Audio/test/processed'
    test_path_unprocessed: './dataVoxCeleb1/Audio/test/wav'
    feat_type: 'spec' #feature type: 'spec' (spectogram), 'logmel' (logmel spectogram)
    sr: 16000
    nfft: 512 #For mel spectrogram preprocess
    window: 0.025 #(s)
    hop: 0.01 #(s)
    nmels: 40 #Number of mel energies
    tisv_frame: 250 #Max number of time steps/frames in input after preprocess
---
model:
    type: 'TResNet34' #model type: 'TResNet32' (Thin ResNet34), 'RNN'
    hidden: 768 #Number of LSTM hidden layer units
    num_layer: 3 #Number of LSTM layers
    proj: 256 #Embedding size
    #Model path for testing, inference, or resuming training
    model_path: './speech_id_checkpoint/final_epoch_950_batch_id_302.model' 
---
train:
    N : 5 #Number of speakers in batch
    M : 10 #Number of utterances per speaker
    num_workers: 0 #number of workers for dataloader
    lr: 0.1
    optim: 'Adam' #optimizer type: 'Adam', 'SGD', 'Adadelta'
    epochs: 1000 #Max training epoch 
    patience: 2
    log_interval: 100 #Iterations before printing progress
    log_file: './speech_id_checkpoint/Stats'
    checkpoint_interval: 50 #Save model after x speaker epochs
    checkpoint_dir: './speech_id_checkpoint'
    restore: !!bool "false" #Resume training from previous model path
